model:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
  adapter_model: "aumoai/llama3.2-3B-lora-oumi-aumogpt-adapter" # "aumoai/llama3.2-3B-qlora-oumi-aumogpt-adapter"
  trust_remote_code: True
  shard_for_eval: True
  model_kwargs:
    load_in_4bit: False

tasks:
  - evaluation_backend: lm_harness
    task_name: mmlu
    num_samples: 10
    eval_kwargs:
      num_fewshot: 5
  - evaluation_backend: lm_harness
    task_name: hellaswag
    num_samples: 50
    eval_kwargs:
      num_fewshot: 10
  - evaluation_backend: lm_harness
    task_name: global_mmlu_pt
    num_samples: 20
    eval_kwargs:
      num_fewshot: 5


output_dir: "eval_results/adapter-lora"